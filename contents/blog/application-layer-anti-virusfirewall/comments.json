[
  {
    "author": "Aodhhan",
    "avatar": "613720a7bae4ce9b3c7a536782671ee9",
    "date": "2007-04-11T12:23:58.000Z",
    "content": "I think the idea is a good one, and is already being used for VPN connections. A computer is put into \"Limbo\" until it is verified to have certain applications, and they are up to date.\r\n\r\nI don't think it would be successful, if the goal was to report on all applications a client computer has before it connected to a host web site. \r\nHowever, I do believe it is possible for Operating Systems and Anti-virus/Anti-Spamware applications to report their presence, status and whether or not they are up-to-date to the browswer (actually to a file which the browser could parse). \r\nThis way, the host web site could interrogate the browser to find out if the operating system is up to date on hot-fixes, a anti-virus is being used and it is also up to date before allowing it full access.\r\nIn today's movement towards Web 2.0 architecture; I think your idea is right on track... and I too, can see this happening in the near future."
  },
  {
    "author": "pdp",
    "avatar": "c4db4e65c9f09f2a373fcaefa5e2bfb4",
    "date": "2007-04-11T13:07:42.000Z",
    "content": "So, I guess Anti-virus agent could supply browser plugins the same way other 3rd-party components (Flash, QuickTime, PDF) do. The client-side script instantiate an anti-virus agent and performs several queries to verify the integrity of the system. If the system is ok, then client is allowed to continue. However, although in general, it sounds like a good idea, I can definitely see situations where the Ant-virus agent provides too much information or it is vulnerable to some type of attack.\r\n\r\nGoode stuff all together.\r\n\r\nHowever, with this post I was trying to show a server-side solution with a little bit of JavaScript that performs simple checks such as what is the current version of PDF and what is the version of QuickTime, etc. Of course this is quite limited.\r\n\r\nI wonder whether browser will support anti-virus or firewall objects in the future. Something like: <strong>window.antivirus</strong> or <strong>window.firewall</strong>"
  },
  {
    "author": "Acidus",
    "avatar": "e78ade355027be37b2192e622b14a46f",
    "date": "2007-04-11T13:30:21.000Z",
    "content": "Repeat after me: You cannot trust the client! At least in a VPN environment you can use certs and digital signatures to ensure the integrity of the binary client. This can't happen with a browser without significant re-architecture.\r\n\r\nI understand your solution is aimed at protecting legitimate users. So you assume no one would bypass the restrictions/enforcement applied to the client just to gain access to the site. Ignoring the social engineering opportunities here (\"Hello, please upgrade to Acrobat 31337, here is the URL...) I am very wary of this idea mainly because of the mistakes devs will make when they are using something that \"verifies the integrity level.\" It's trivial for the devs to make the small (and faulty) logical leap and think that now the client is somehow trusted. I can easily imagine a dev using this system saying something like \"well, if they got this far, I know they are safe, so let's do [insert bad security practice here].\"\r\n\r\nI think this idea is interesting, but I worry that it will create a false sense of security in the client that causes devs to make silly mistakes. Of course, they are already making silly mistakes... :-)"
  },
  {
    "author": "Sp0oKeR",
    "avatar": "3c5103f613c394651ced1e7b48eaa66b",
    "date": "2007-04-11T13:34:39.000Z",
    "content": "Maybe if Anti-Virus solutions use project like http://www.security-database.com/ssa.php it'll  be very nice! =)\r\n\r\nNice Article and idea =)\r\n\r\nRegards,\r\n\r\nSp0oKeR"
  },
  {
    "author": "Jordan",
    "avatar": "bd38ec8896a46f6a173c7b80aac0d5be",
    "date": "2007-04-11T13:35:19.000Z",
    "content": "Instead of Anti-Virus the current buzzwords would either be \"Content Filtering\" or \"Endpoint Compliance\" depending on which particular aspect you're talking about.  Either way, Anti-Virus isn't ambiguous -- it's just wrong.  ;-)\r\n\r\nIt's a really interesting idea in general, but here's one problem I see -- if the user's browser is compromised, /ANY DATA/ from the browser is suspect.  That means your windows.antivirus or windows.firewall object is too.  The threat isn't that the /user/ will try to bypass the protection to access the site, so much as it is that malware on the machine (or malscripts, or whatever) will try to bypass the protection for the site.\r\n\r\nOf course, even in that case, if you assume that the client has a period of time where he's not infected but is vulnerable and visiting the site, this idea might work to help get him to upgrade faster, so it's still got potential.\r\n\r\nYou'll run into the exact same situation that Cisco finds themselves in now with their NAC being subverted:\r\n\r\nhttp://www.darkreading.com/document.asp?doc_id=120852"
  },
  {
    "author": "Arthur",
    "avatar": "1b0bb45037a508d0fe17cfdc3ee747f1",
    "date": "2007-04-11T13:40:34.000Z",
    "content": "This idea has been worked on by companies like wholesecurity and Sygate, both of whom were purchased by Symantec, particularly on the securing the VPN front."
  },
  {
    "author": "Ivan Ristic",
    "avatar": "f1878ff2452d711a658b4ceea142b602",
    "date": "2007-04-11T13:44:38.000Z",
    "content": "Actually, I think the term Application Layer Firewall should be used to protect all sides involved in communication, servers (applications) and clients equally. Although ModSecurity is typically seen as a solution to protect the server-stuff this is just a matter of perception. For example, you can configure Apache to work as a forward proxy, add ModSecurity to it, and configure your the network to force all clients to go through Apache for their HTTP needs. In this situation ModSecurity will protects the clients, as it allows you to inspect the content before it is delivered. While it is true that ModSecurity is better equipped to protect the server-side this is only the current situation. Improving support for forward-proxy deployments in on my TODO list.\r\n\r\nFYI, I have already experimented with content injection in ModSecurity (i.e. a server-side Greasemonkey). This feature will be published later this month as part of ModSecurity v2.2-dev1  and discussed in my presentation at OWASP Europe in Italy in May (http://www.owasp.org/index.php/6th_OWASP_AppSec_Conference_-_Italy_2007/Agenda)."
  },
  {
    "author": "PoYoX",
    "avatar": "4ee8c79475231fce556c5649fc5a0bab",
    "date": "2007-04-11T14:01:50.000Z",
    "content": "I'm not shure that a site could be compromise by a vulnerable client. I have seen 2 approaches to make a solution for the client side :\r\n\r\n1. Some guy from Hauri Antivirus tell us in a conference about the solution in the Asian Banks. They developed an ActiveX component to verify the integrity of the machine (not only the browser) before the client could get into the bank page.\r\n\r\n2. There is SpyBye, a tool for checking URLs while browsing. From the site : \"It functions as an HTTP proxy server and intercepts all browser requests. SpyBye uses a few simple rules to determine if embedded links on your web page are harmlesss, unknown or maybe even dangerous\"\r\n\r\nI think this topic on securing web clients for malicius server its very hot now.\r\n\r\nRegards"
  },
  {
    "author": "Tom",
    "avatar": "96c56304cc6ce9720734353bf2305812",
    "date": "2007-04-11T14:01:53.000Z",
    "content": "I'm sorry, but this solution just won't work.  If you have an application that is vulnerable to XSS, you can't implement JavaScript functionality that would reliably protect the client.  There is no way to prevent my injected JavaScript from simply overwriting all of your functions, for example.\r\n\r\nThe only way to implement real client-side protection is to incorporate that functionality into the browser.  There are a number of Firefox plugins that attempt to address this problem, like Firekeeper.  I'm not sure how well they work, but at least they have the potential to help address the problem.  JavaScript just isn't able to do that."
  },
  {
    "author": "pdp",
    "avatar": "c4db4e65c9f09f2a373fcaefa5e2bfb4",
    "date": "2007-04-11T15:09:38.000Z",
    "content": "wow, so many comments in such a short time...\r\n\r\nAcidus,\r\nWe don't really need to architecture the whole thing. All we need to do is to somehow make sure that the client integrity is not compromised. In many cases that won't work. However, even if it improves the situation with just 30%, I believe that it worth the effort. There is no secure system for as long as it needs to be used. All we need to do is to find the balance between security and accessibility.\r\n\r\nJordan,\r\nWell yes, if the client system is compromised by some sort of malware then everything that comes in or goes out is also subjected to attacker's whishes. However, this is not the point I am trying to make. This system protects when the client machine is not fully patched and it could be compromised on the way.\r\n\r\nIvan,\r\nI am not sure what server-side Greasemonkey scripts do but one particular instance where ModSecurity fails to protect is when the client-side logic is also vulnerable to something like DOM-based XSS. We are going to see a lot more of these in the future mainly because everyone goes AJAX. How does ModSecurity protects against the PDF UXSS issue?\r\n\r\nTom,\r\nYou are right, we cannot prevent XSS injected JavaScript to overwrite certain functions. However, it is the server-side component job to prevent this thing from happening at first place. Moreover, I've seen some AJAX solutions (GMail) where the structure of the application is so weird that if you try to replace or wrap particular functionalities you almost end up with breaking everything."
  },
  {
    "author": "Aodhhan",
    "avatar": "613720a7bae4ce9b3c7a536782671ee9",
    "date": "2007-04-11T15:53:57.000Z",
    "content": "I don't think anyone made the claim this would be the security invention of the century. \r\n\r\nTo be honest; I don't trust one single appliance, application, user, administrator or client which touches a network. Every one of them can be defeated. \r\nHence security professionals implement a policy of \"defense in depth\". \r\n\r\nSaying that something won't work because... displays ignorance. \r\n\"What if it becomes compromised...\" pretty much works on everything. \r\n\r\nFirewalls won't work, because... they can be compromised. Proxy's won't work because they can be bypassed. Certificates won't work because I can make a copy of it. VPN's won't work because of all of the above. Wireless won't do because the signal can be intercepted and decrypted. Can't use Windows, UNIX, Linux, Oracle or thousands of applications because there are vulnerabilities to them.\r\n\r\nIt is easy to say something will not work or cannot be done. What makes you the big dollars and gives you credibility, is finding out ways to make it work.\r\n\r\nThe idea is still a good one. Another possible future choice for defense in depth."
  },
  {
    "author": "celf",
    "avatar": "a4983017bc7269243891f588ca9121d4",
    "date": "2007-04-12T04:14:39.000Z",
    "content": "pdp -\r\n\r\nYou responded to Tom by talking about the server side. Yup, that's the place to do it alright (but isn't this a discussion of client side protection?). Heck, we can fix all this jive by proper server side output encoding.\r\n\r\nYou stated above \"...site.com informs Joe that unless he patches his system, he wonâ€™t be allowed to enter.\" I don't really think that a business that runs an app with thousands of users is going to start turning them away because they run some antiquated or unpatched browser. Not for any customer I've ever assessed (lots). That could mean lost revenue, and that's just as unacceptable as a security issue."
  },
  {
    "author": "GSE",
    "avatar": "206390c2dc812f35ca8aaa11ffecc840",
    "date": "2007-04-14T01:58:15.000Z",
    "content": "I personally believe that you cannot dictate security controls to a customer.   In your example, if Joe is unable to access site.com due to patching issues, I would think that Joe would simply go to competitors.com and perform his transactions elsewhere.  VPN is not really a good analogy for this since most VPN users have no other choices.  For websites (especially ecommerce), individuals do have a choice.\r\n\r\nInmy opinion, the only way to ensure that a site is secure is a multi-pronged approach: \r\n\r\n- Ensure that security is a fundamental part of the defined SDLC that is used to create the web application.\r\n\r\n- Have a defined response plan to be able to evaluate, prioritize, test, and remediate vulnerabilities found within the application's architecture and the application itself.\r\n\r\n-Realize that there is always going to be a risk in doing business on the web and take server side controls to mitigate that risk. One item that I am surprised that I do not see used more is something that banks/credit card issuers do to help protect themselves: profile the normal usage of an application and alert on behaviour that falls outside the norm.\r\n\r\nApplication firewalls, at least in my experience, seem to cause some more issues than what they solve.  I know of multiple businesses that deployed app firewalls where it became harder to ensure that the applications were written with security in mind.  Input validation was not focused on because \"the appfirewall does that for us\".  Product management started to spend money that was currently allocated to security functionality on other items since \"the application firewall does a better job\".  Deploying application firewalls requires a lot of level setting on the amount of security that it truly gives an organization."
  },
  {
    "author": "pdp",
    "avatar": "c4db4e65c9f09f2a373fcaefa5e2bfb4",
    "date": "2007-04-14T08:01:36.000Z",
    "content": "GSE, interesting points all together."
  }
]