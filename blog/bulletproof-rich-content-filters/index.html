<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Bulletproof Rich-content Filters</title><meta name="description" content="It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don't know how things work without first taking them apart."><meta property="name" content="Bulletproof Rich-content Filters"><meta itemprop="name" content="Bulletproof Rich-content Filters"><meta property="description" content="It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don't know how things work without first taking them apart."><meta itemprop="description" content="It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don't know how things work without first taking them apart."><meta property="image" content="http://s.wordpress.com/mshots/v1/https%3A%2F%2Fwww.gnucitizen.org%2Fblog%2Fbulletproof-rich-content-filters%2F?w=1024"><meta itemprop="image" content="http://s.wordpress.com/mshots/v1/https%3A%2F%2Fwww.gnucitizen.org%2Fblog%2Fbulletproof-rich-content-filters%2F?w=1024"><meta property="og:type" content="website"><meta property="og:url" content="https://www.gnucitizen.org/blog/bulletproof-rich-content-filters/"><meta property="og:title" content="Bulletproof Rich-content Filters"><meta property="og:description" content="It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don't know how things work without first taking them apart."><meta property="og:image" content="http://s.wordpress.com/mshots/v1/https%3A%2F%2Fwww.gnucitizen.org%2Fblog%2Fbulletproof-rich-content-filters%2F?w=1024"><meta name="twitter:title" content="Bulletproof Rich-content Filters"><meta name="twitter:description" content="It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don't know how things work without first taking them apart."><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://s.wordpress.com/mshots/v1/https%3A%2F%2Fwww.gnucitizen.org%2Fblog%2Fbulletproof-rich-content-filters%2F?w=1024"><link type="text/css" href="/blog.css" rel="stylesheet"><script type="text/javascript" src="/blog.js"></script></head><body><header id="header"></header><nav id="topnav"><ul><li><a href="/">Home</a></li><li><a href="/projects.html">Projects</a></li><li><a href="/files">Files</a></li><li><a href="/about.html">About</a></li></ul></nav><article><div id="content"><h1 class="title">Bulletproof Rich-content Filters</h1><div class="date">Tue, 18 Dec 2007 11:13:28 GMT</div><div class="author">by
<a href="/members/pdp.html">pdp</a></div><div id="post-content"><p>It is true that here, at GNUCITIZEN, we try to look more on the offensive side of the things rather then the defensive side. I personally find that perfectly fine and ethical since you need people from both camps. Not, that we are the bad guys, (we are whitehats) but we primarily concentrate on how to break things. As such, we are part of the information security food chain. Some break, others fix. Some of us destroy, others build upon. And there is a lot of value in breaking things. More then you can imagine! It is a simple fact that you don&#39;t know how things work without first taking them apart.</p>
<p>Though, once in a while, we try to show how to fix problems by using what we have learned along the way. This is exactly what I am planning to do today. In the this post I will briefly introduce you to some of the concepts that have build up with the time, about how to allow rich user-supplied content such as HTML and still guarantee a bulletproof security. Keep in mind that although the proposed mechanism works perfectly fine, there is always a chance to screw up. In that case you should blame no one but yourself.</p>
<blockquote>
<p>Before I continue I must say that I haven&#39;t pioneered the here discussed techniques. I don&#39;t know who did but what I know is that there are several tools (<a href="http://www.owasp.org/index.php/Category:OWASP_AntiSamy_Project">AntiSamy</a>) that already implement them. Though, I will add my own twist to the overall concept.</p>
</blockquote>
<p>Let&#39;s glance through the problem: &quot;The fast world of Web2.0 moves towards what is known as _User-supplied Rich Content_, _Data in the Cloud_, etc. In this model the user supplies all the data in a rich way. The user is able to define HTML, execute client-side JavaScript and even execute server-side JavaScript. The problem is that in order for the user to do all of that in a secure manner, there must be an excellent understandings of what is malicious so that the bad input can be sanitized. Think about MySpace, for example. The users can define their own HTML and CSS for their home pages. Of course, MySpace needs to guarantee that the user-supplied HTML wont effect the owner or any other visitor arriving on the personal profile. This is a hard task which often involves a lot of sanitization, blacklistings, whitelistings, filters, etc, etc, etc. It is fair to say that the model is insecure by design. But is there something that we can do about it and will that something guarantee good enough security?&quot;</p>
<p>The simple fact is that it is possible to lockdown a special cases like the one discussed above. Not only it is possible but also it can be made bulletproof and extremely reliable. One of the key problems that rich-content applications face today is that it is very hard to detect malicious input. This is due to the enormous amount of differences between client-side technologies. One type of expression may render in Firefox and at the same time fail in IE. Not only that, but the Web Apps&#39; World is changing so drastically that it is not even feasible anymore to perform security checks based on whatever filtering mechanism you might have implemented.</p>
<p>Some security folks suggest a security model which I believe may work if all vendors start working together. We all know that this will never happen. The proposed model consists of several stages where first of all browsers and client-side technologies become compatible with each other and then a common sandboxing mechanism is invented where the data is clearly separated from the logic. It makes sense but as I said it wont work. So, what can we do on the server-side in order to improve the situation?</p>
<p>Your best chances is to find the secure/compromisable common dominator between client-side technologies and use that as a base. How do we do that? Let&#39;s take a look at HTML for example.</p>
<h2 id="stage1-the-intermediate-format">Stage1: The Intermediate Format</h2>
<p>So in our case we have a scenario where we want to allow the user to upload rich content in a form of HTML but at the same time somehow to sandbox the content in such a way that no malicious activities can be performed. Due to the fact that HTML is based on SGML and both of them allow tags to overlap, i.e it is not XML, it is very hard to make use of regular expressions in order to secure the content. Our best bet is to convert the content to an intermediate format which can be examined.</p>
<p>At the first stage we get junk from the user, which we don&#39;t trust, and convert it to something that we can guarantee that is at least machine-readable. The best choice for this machine-readable format is XML, mainly because it is fairly easy to parse and analyse and there are more then enough tools that can deal with this problem. So, we receive the random text from the user and we convert it to XML. How do we convert junk into XML? This is kind of trivial. There are many implementations of the so called <a href="http://tidy.sourceforge.net/">HTML Tidy</a> engine. HTML Tidy receives a text and cleans it up to an extend where the result is well formatted XML or XHTML if you like.</p>
<p><em>Stage1 completed!</em></p>
<h2 id="stage2-the-compliance-checks">Stage2: The Compliance Checks</h2>
<p>I bet a lot of your already know where this thing is going. But don&#39;t jump of your seats yet. You are probably thinking to parse the XML and do your crazy magic but if you go on this read you are already getting into trouble and probably reversing the good effect of the XML potion. Let&#39;s keep it simple. Instead of parsing the XML yourself, like the AntiSamy guys did, you should use tools that already does the same and are already been extensively tested for compatibility and security problems. For this type of purpose I would suggest to use XSD (XML Schema Definition).</p>
<p>In XSD we can define/whitelist the syntax that we think is fine for the user to use. For example, we can define that the user can supply a <code>&lt;p&gt;</code> tag, which may only contain whitespaces, text and <code>&lt;img&gt;</code> tags. On the other hand, each <code>&lt;img&gt;</code> tag may only have one attribute known as <code>src=</code> which is of a type <code>URL</code>. And the <code>URL</code> type may only contain strings that start with <code>http://</code> or <code>https://</code>. There are a plenty of tools that will allow you to engineer the definition in a graphical way. It is really simple especially when you are using tools like Altove XMLSpy.</p>
<p>So, what do we do with XML and XSD? You are right, we match them. If the XSD matches the XML then the user has passed the check and the content is guaranteed to be none-malicious. There you go!</p>
<h2 id="things-to-watch-out-for">Things to watch out for</h2>
<p>I said that there is always a chance to screw up. And probably you will unless you really know what you are doing. I personally won&#39;t allow <code>&lt;img&gt;</code> tags at all unless the <code>src=</code> attribute points to a real image file on a domain that I control. So for example, if you want your users to upload image files and then reference them from their pages with <code>&lt;img&gt;</code>, what you should probably do is to put all the images on a separate domain like <code>static.yourdomain.com</code> and make sure that your XSD matches against it for <code>URL</code> types. This will reduce the impact of CSRF attacks to an extend. It is also important to check the format of the files users can upload and deny write access if the don&#39;t match against any of your safe file formats. Etc!</p>
<blockquote>
<p>So what does all that mean? It simply means that you can make a bulletproof rich-content filter, but this is just 10% from the whole journey. It also means that, there are 100% bulletproof filters, but not 100% bulletproof security models. The highest you can go with security is about 50% and I&#39;ve been actually generous. The simple fact is there is nothing on this planet that cannot be hacked. If someone can use it, so attackers can. If you start living with this idea for a while, you will start perceiving the truth as it is.</p>
</blockquote>
</div><div id="post-comments"><p><em>Archived Comments</em></p><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/645ade6965ddd0b8b4ceff68538a1203?s=256&amp;d=retro" alt="Thomas Roessler"><span class="post-comment-author">Thomas Roessler</span><div class="post-comment-content">This sounds like the kind of stuff that the W3C HTML working group should hear.

See here for joining instructions: http://www.w3.org/html/wg/#who</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/c4db4e65c9f09f2a373fcaefa5e2bfb4?s=256&amp;d=retro" alt="pdp"><span class="post-comment-author">pdp</span><div class="post-comment-content">Thomas, sure I can, but it will be better if someone transmits the message to the people who need to know about it. :)</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/4dac203be4e70cc420e7b853b6a84505?s=256&amp;d=retro" alt="tenest"><span class="post-comment-author">tenest</span><div class="post-comment-content">Not that this is a big deal, but XML Spy is by AltovA not AltovE.  http://www.altova.com/</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/7fbd6be0fb0acd878c35d5c49c485933?s=256&amp;d=retro" alt="Sverre Johansen"><span class="post-comment-author">Sverre Johansen</span><div class="post-comment-content">If I understand you correct this parser would drop any message that contains invalid (evil) markup. What you usually want is a parser that drops the invalid parts and produces a safe version. 

Is there any way of specifying what is legal in a formal way (like XML Schema, as you suggest, or RelaxNG), and then drop the invalid parts?</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/c4db4e65c9f09f2a373fcaefa5e2bfb4?s=256&amp;d=retro" alt="pdp"><span class="post-comment-author">pdp</span><div class="post-comment-content">Sverre, hmmm, this is the hard bit. But I don't see why you have to be so user friendly. If the markup looks different from what you allow you should really say <strong>stop</strong> to the user and ask them to rephrase their input.</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/7fbd6be0fb0acd878c35d5c49c485933?s=256&amp;d=retro" alt="Sverre Johansen"><span class="post-comment-author">Sverre Johansen</span><div class="post-comment-content">That would be a usability tradeoff, in my opinion. It is probably OK for small texts such as comments and descriptions, but not that suited for larger content such as a blog post. People are used to being able to write tagsoup and the browser will figure it out for them, it's really the same with security validation. A blogger might not know that the recipe he found for having a floating CSS menu (or whatever), could also be used for phishing. The content could even be something produces by Microsoft Word.

It's kind of like how the web works, even if we like it or not :)</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/c4db4e65c9f09f2a373fcaefa5e2bfb4?s=256&amp;d=retro" alt="pdp"><span class="post-comment-author">pdp</span><div class="post-comment-content">yes, I see your point. I don't see why it shouldn't be possible to strip out anything that does not much the XML Definition. Though, I am not aware of how this can be done in practice. It might be the case of converting the XML Definition into XML Stylesheet which only extract the parts that are safe and produce a normalized document. That might be a good solution.</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/504b32a2f9a4212c4a2f139fdd7a8b1e?s=256&amp;d=retro" alt="ArkanoiD"><span class="post-comment-author">ArkanoiD</span><div class="post-comment-content">I'd go for schema for "compliance" and XPath-based filter for extra filtering rules if there is need in more restructions..</div></div><div class="post-comment"><img class="post-comment-avatar" src="//gravatar.com/avatar/8c80c44ed05803212488c7257f8ff429?s=256&amp;d=retro" alt="arshan"><span class="post-comment-author">arshan</span><div class="post-comment-content">there are a few problems with using xsd after you turn the input into the predictable xhtml format. if i had not been so rushed and drained in san jose we could have talked about this.

a) xsd is a blanket yes/no validation, so the application can't provide the user any feedback on how their input was altered. you may want to prevent any information leakage if you're a hardcore security person, but that's not very usable, especially for the myspace scenario when you want to help the user tune their input. i want the antisamy project to be an enabler - help give the little guy some functionality that has been totally reserved for the big players, and feedback is one way antisamy can differentiate you from others, safely.

b) an xsd would have a very difficult time parsing cascading style sheets (which AntiSamy does, safely). if you're attacking antisamy, you can't provide a z-index, position values other than auto/inherit, and other CSS tricks that could lead to phishing.

c) since antisamy doesn't retain all the extra functionality that an xsd parser has, it has a lighter footprint and doesn't have any of the xsd parser's attack surface.

there are benefits of using xsd, of course: speed, stability, better supported code.</div></div></div></div></article><footer id="footer"><p>Copyright &copy; 2024 <a href=""></a>. All rights reserved.</p></footer></body></html>